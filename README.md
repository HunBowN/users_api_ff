#### Проблемы, которые нужно было решить и решения

1) ##### Как создать таблицу и парсить данные?
Чтобы не создавать таблицу вручную и для дальнейшего парсинга данных написал рекурсивную функцию, которая доставала все вложенные данные и назначала соответствующие ключи для полей(с учетом вложенности, тк были и те поля что повторялись), использовать нативную array_walk_recursive было нельзя т.к она не учитывает ключи если есть вложенные массивов;
2) ##### Выбор метода и количества запрашиваемых и вставляемых данных за итерацию
- **запрос данных от api**
столкнувшись с первыми проблемами отдачи больших объемов данных(429 ошибка), посетил github данного проекта нашел конфиг, выяснил, что установлены след-е лимиты: 5к юзеров за 1 запрос, 20к юзеров подряд, даунтайм 300с после запроса 20к юзеров, от этого и отталкивался - в функции в цикле делаю 4 запроса по 5к юзеров, если выпадает ошибка, показываю  на фронте, включаю таймер обратного отсчета
- **insert в бд**
Для быстрого и эффективного insert такого объема данных выбрал PDO::beginTransaction. Во-первых, это правильно и секьюрно, во-вторых, для повышения производительности массовой вставки одна из первых рекомендаций - отключить режим автоматической фиксации транзакции, что и делает данная функция.
Из информации которую изучил и проведенных бенчмарков принял решение вставлять 1000 записей за 1 insert, в итоге 5к записей добавляются ~1c
В основном пользовался официальной информацией доля оптимизации *https://dev.mysql.com/doc/refman/8.0/en/optimizing-innodb-bulk-data-loading.html*

3) ##### Оптимизация скорости работы метода выборки родственников
Для решения этой проблемы нужно было добавить индекс по колонкам с фамилией и городом(по которым мы делаем выборку)
Локально на Маке запрос при любом размере таблицы > 300к записей и практически любым лимитом запсией в запросе сократился от 400ms без индексов до<100ms с ними; на хосте, на который я задеплоил к сожалению тайминг чуть выше, так как хост стоковый с 1м ядром, самый дешевый/слабый;

 ##### Дополнительно
 - Для удобного деплоя использовал Docker все конфиги для наглядности залил в github, в том числе с настройками бд  */docker/mysql/my.cnf*
 - Есть другой способ решения данного тестого с использованием LOAD DATA INFILE и LOAD DATA XML, api с юзерами может отдавать данные в этих форматах, могу сделать в качестве патча к этому тз.